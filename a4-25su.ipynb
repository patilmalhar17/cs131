{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbc536e-eeec-4e47-bfb6-6c61f6dba617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------+\n",
      "|passenger_count|pulocationid|dolocationid|total_amount|\n",
      "+---------------+------------+------------+------------+\n",
      "|            1.0|       239.0|       239.0|         8.8|\n",
      "|            1.0|       230.0|       100.0|         8.3|\n",
      "|            1.0|        68.0|       127.0|       47.75|\n",
      "|            1.0|        68.0|        68.0|         7.3|\n",
      "|            1.0|        50.0|        42.0|       23.15|\n",
      "|            1.0|        95.0|       196.0|         9.8|\n",
      "|            1.0|       211.0|       211.0|         6.8|\n",
      "|            1.0|       237.0|       162.0|         7.8|\n",
      "|            1.0|       148.0|        37.0|        20.3|\n",
      "|            1.0|       265.0|       265.0|        0.31|\n",
      "+---------------+------------+------------+------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Part 1\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Fare Prediction\").getOrCreate()\n",
    "\n",
    "# Load the CSV\n",
    "df = spark.read.csv(\"2019-04.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Choose the columns at indices 3, 7, 8, 16 since it starts at 0\n",
    "selected_cols = [df.columns[3], df.columns[7], df.columns[8], df.columns[16]]\n",
    "\n",
    "df_selected = df.select(*selected_cols)\n",
    "\n",
    "# Show the first 10 rows\n",
    "df_selected.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "747ddc4c-560f-4dd1-80b5-ce144f1ca186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "trainDF, testDF = df_selected.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45dd3202-a697-4204-ade1-e946060c380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# feature_cols has all 4 columns from selected_cols except the last one, total_amount\n",
    "feature_cols = selected_cols[:-1] \n",
    "\n",
    "# Single vector called assembler\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Predicts the total_amount which is last column in selected_cols\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=selected_cols[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79539b15-194c-4d69-b0be-079687d1973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52baad31-acba-4d78-9de6-d6f2299efd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_1 in memory! (computed 28.4 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_1 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 28.4 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_6 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 28.4 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_2 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_3 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_3 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_0 in memory! (computed 28.4 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_0 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_4 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_7 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_7 to disk instead.\n",
      "25/07/26 18:27:51 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:51 WARN BlockManager: Persisting block rdd_106_5 to disk instead.\n",
      "25/07/26 18:27:52 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 70.0 MiB so far)\n",
      "25/07/26 18:27:52 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:52 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 42.9 MiB so far)\n",
      "25/07/26 18:27:52 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 70.0 MiB so far)\n",
      "25/07/26 18:27:53 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:53 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 28.6 MiB so far)\n",
      "25/07/26 18:27:53 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:53 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 70.0 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 12.7 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 28.6 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 70.0 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 28.6 MiB so far)\n",
      "25/07/26 18:27:54 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 70.0 MiB so far)\n",
      "25/07/26 18:27:55 WARN MemoryStore: Not enough space to cache rdd_106_5 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:55 WARN MemoryStore: Not enough space to cache rdd_106_2 in memory! (computed 19.1 MiB so far)\n",
      "25/07/26 18:27:55 WARN MemoryStore: Not enough space to cache rdd_106_4 in memory! (computed 28.6 MiB so far)\n",
      "25/07/26 18:27:55 WARN MemoryStore: Not enough space to cache rdd_106_6 in memory! (computed 70.0 MiB so far)\n"
     ]
    }
   ],
   "source": [
    "# Part 5\n",
    "\n",
    "# Trains pipeline on training data\n",
    "model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70dae648-762b-438e-9c0d-3c201cc828e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+------------+------------+------------------+\n",
      "|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n",
      "+---------------+------------+------------+------------+------------------+\n",
      "|            0.0|         1.0|         1.0|       103.3|27.714119597463643|\n",
      "|            0.0|         4.0|         4.0|         6.8|27.714119597463643|\n",
      "|            0.0|         4.0|        33.0|       31.55|21.079365103486097|\n",
      "|            0.0|         4.0|        79.0|         7.8|21.079365103486097|\n",
      "|            0.0|         4.0|       107.0|        11.8|21.079365103486097|\n",
      "|            0.0|         4.0|       144.0|        11.3|21.079365103486097|\n",
      "|            0.0|         4.0|       234.0|        11.0|21.079365103486097|\n",
      "|            0.0|         7.0|       121.0|        28.8|21.079365103486097|\n",
      "|            0.0|         7.0|       223.0|         6.8|21.079365103486097|\n",
      "|            0.0|         7.0|       223.0|         8.3|21.079365103486097|\n",
      "+---------------+------------+------------+------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Part 6\n",
    "\n",
    "# Apply model to testing dataset\n",
    "predict = model.transform(testDF)\n",
    "\n",
    "# Show first 10 rows for selected_cols, actual total_amount, and prediction\n",
    "predict.select(*feature_cols, selected_cols[-1], \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77fceb6c-750f-4b2c-9da1-4058c9b3fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 12.576215578903543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Part 7\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=selected_cols[-1], predictionCol=\"prediction\", metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator.evaluate(predict)\n",
    "print(f\"RMSE = {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
